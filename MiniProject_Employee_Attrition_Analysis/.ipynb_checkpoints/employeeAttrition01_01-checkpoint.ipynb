{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "sns.set(color_codes = True)\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'IBM-Employee-Attrition.csv'\n",
    "\n",
    "# import cafe listings into dataframe\n",
    "emp = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp[emp.Over18!='Y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = emp.drop(columns=['EmployeeCount', 'EmployeeNumber','Over18'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=emp,hue='Attrition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attrition_map={'Yes':1,'No':0}\n",
    "emp['Attrition'] = emp['Attrition'].map(attrition_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(data):\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(data.corr(), dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(30, 25))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(data.corr(), mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_heatmap(emp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(12,7))\n",
    "sns.heatmap(emp.corr()[['Attrition']].sort_values('Attrition',ascending=False),annot=True, cmap='coolwarm', center=0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all numerical columns\n",
    "numerical_dtypes = ['int16','int32', 'int64','float16','float32','float64']\n",
    "num_cols = []\n",
    "for i in emp.columns:\n",
    "    if emp[i].dtype in numerical_dtypes:\n",
    "        num_cols.append(i)\n",
    "        \n",
    "print(len(num_cols))\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all category columns\n",
    "\n",
    "cat_cols = list(set(emp.columns) - set(num_cols))\n",
    "print(len(cat_cols))\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sale price of all numerical columns\n",
    "\n",
    "def plot_multi_charts(data, x_column_list, y, title, y_label, plot_type, figsize):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4, top=0.975)\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    for i, col in enumerate(list(data[x_column_list]),1):\n",
    "        \n",
    "        ax = fig.add_subplot(len(x_column_list), 3, i)\n",
    "        \n",
    "        if plot_type == 'scatter':\n",
    "            plt.scatter(x=data[col], y=data[y])\n",
    "            plt.xlabel('{}'.format(col), size=15,labelpad=12.5)\n",
    "            plt.ylabel(y_label, size=15, labelpad=12.5)\n",
    "        elif plot_type == 'bar':\n",
    "            data.groupby(col).plot.bar(ax=ax)\n",
    "    \n",
    "    figname = title + '.png'\n",
    "    fig.savefig(figname,transparent=False, bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    print('Total cols: ',len(x_column_list))    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe sale price of all numerical features\n",
    "\n",
    "plot_multi_charts(data=emp, x_column_list=num_cols,y='Attrition', \n",
    "                  title='SalePrice vs numerical features',y_label='SalePrice',plot_type='bar',figsize=(18,180))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,100))\n",
    "fig.subplots_adjust(hspace=1.2, wspace=0.5, top=0.975)\n",
    "\n",
    "for i, col in enumerate((num_cols),1):\n",
    "    ax = fig.add_subplot(len(num_cols), 3, i)\n",
    "    sns.distplot(emp[col])\n",
    "    plt.xlabel('{}'.format(col), size=15,labelpad=12.5)\n",
    "    plt.ylabel('Frequecy', size=15, labelpad=12.5)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri_yes = emp[emp.Attrition==1]\n",
    "attri_no =  emp[emp.Attrition==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pair_charts(data1, data2, column_list, legend_text,fig_size):\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    fig.subplots_adjust(hspace=1, wspace=0.5, top=0.96)\n",
    "    fig.suptitle('Attrtion Yes vs No')\n",
    "\n",
    "    for i, col in enumerate(list(data1[column_list]),1):\n",
    "        # print(col)\n",
    "        ax = fig.add_subplot(len(column_list), 3, i)\n",
    "        plt.hist(data1[col],alpha=0.8)\n",
    "        plt.hist(data2[col],alpha=0.8)\n",
    "        plt.xlabel('{}'.format(col), size=15,labelpad=12.5)\n",
    "        plt.ylabel('Frequecy', size=15, labelpad=12.5)\n",
    "        plt.legend(legend_text)\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    #figname = 'High vs Low quality houses.png'\n",
    "    # fig.savefig(figname,transparent=False, bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bar charts of ordinal features \n",
    "cols_to_plot = cat_cols\n",
    "plot_pair_charts(attri_no,attri_yes,cols_to_plot,legend_text=['Attrition No','Attrition Yes'],fig_size=(15, 30))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bar charts of numerial features \n",
    "cols_to_plot = num_cols\n",
    "plot_pair_charts(attri_no,attri_yes,cols_to_plot,legend_text=['Attrition Yes','Attrition No'],fig_size=(15, 58))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1 = ['WorkLifeBalance',\n",
    "         'JobSatisfaction',\n",
    "         'JobInvolvement',\n",
    "         'YearsAtCompany',\n",
    "         'StockOptionLevel',\n",
    "         'YearsWithCurrManager',\n",
    "         'Age',\n",
    "         'MonthlyIncome',\n",
    "         'YearsInCurrentRole',\n",
    "         'JobLevel',\n",
    "         'TotalWorkingYears']\n",
    "\n",
    "cols2 = ['DistanceFromHome',\n",
    "        'NumCompaniesWorked',\n",
    "        'PerformanceRating',\n",
    "        'HourlyRate',\n",
    "        'PercentSalaryHike',\n",
    "        'Education',\n",
    "        'YearsSinceLastPromotion',\n",
    "        'RelationshipSatisfaction',\n",
    "        'DailyRate',\n",
    "        'TrainingTimesLastYear']\n",
    "\n",
    "feature_cols = cols1 + cols2\n",
    "\n",
    "target_col = 'Attrition'\n",
    "\n",
    "# feature_cols = [c for c in emp.columns if c != target_col]\n",
    "\n",
    "X = emp[feature_cols]\n",
    "\n",
    "y = emp['Attrition']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC_curve(model,X_test,y_test):\n",
    "\n",
    "    # Generate the prediction values for each of the test observations using predict_proba() function rather than just predict\n",
    "    preds = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Store the false positive rate(fpr), true positive rate (tpr) in vectors for use in the graph\n",
    "    fpr, tpr, _ = roc_curve(y_test, preds)\n",
    "\n",
    "    # Store the Area Under the Curve (AUC) so we can annotate our graph with theis metric\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot the ROC Curve\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw = lw, label = 'ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color = 'navy', lw = lw, linestyle = '--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train,y_train)\n",
    "dummy_clf.predict(X_test)\n",
    "dummy_clf.score(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOMFOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(criterion='gini',\n",
    "                                max_depth=7, \n",
    "                                random_state=1)\n",
    "\n",
    "rf_clf.fit(X_train,y_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "ac = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "    \n",
    "plot_ROC_curve(rf_clf,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=None,class_weight='balanced')\n",
    "dtc.fit(X_train,y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "ac = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "plot_ROC_curve(dtc,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "\n",
    "lin_model = LogisticRegression(solver='liblinear')\n",
    "lin_model.fit(X_train, y_train)\n",
    "lin_model.score(X_test, y_test)\n",
    "\n",
    "y_pred = lin_model.predict(X_test)\n",
    "ac = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "plot_ROC_curve(lin_model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPPORT VECTOR MACHINE\n",
    "\n",
    "\n",
    "# svc_model = SVC(kernel='linear', probability=True)\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)\n",
    "svc_model.score(X_test, y_test)\n",
    "\n",
    "y_pred = svc_model.predict(X_test)\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# plot_ROC_curve(svc_model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp['Attrition'].value_counts(normalize=True).plot(kind='bar')\n",
    "\n",
    "# plt.bar(x, height= y)\n",
    "\n",
    "for i, v in enumerate(emp['Attrition']):\n",
    "    plt.text(xlocs[i] - 0.25, v + 0.01, str(v))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp['Attrition'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot test accuracy by number of neighbors:\n",
    "test_acc = []\n",
    "for i in range(1, 399):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    test_acc.append(knn.score(X_test, y_test))\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(list(range(1, 399)), test_acc, lw=3.)\n",
    "plt.show()\n",
    "print('Highest accuracy is', round(max(test_acc),2), ' when k=', test_acc.index(max(test_acc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "mcv_accuracy=[]\n",
    "\n",
    "for k in np.arange(1,365):\n",
    "    knclf_x = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "    cv_score = cross_val_score(knclf_x,X_train,y_train,cv=5)\n",
    "    mcv_accuracy.append(cv_score.mean())\n",
    "    \n",
    "# cv_accuracy\n",
    "\n",
    "print('Highest accuracy is', round(max(mcv_accuracy),3), ' when k=', mcv_accuracy.index(max(mcv_accuracy)))\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(np.arange(1,365),mcv_accuracy,linestyle='dashed',marker='.',markerfacecolor='red', markersize=10)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('mean cv_accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "max_neighbors = np.floor(X.shape[0] - X.shape[0]/5.)\n",
    "\n",
    "print(max_neighbors)\n",
    "max_neighbors=399\n",
    "\n",
    "# plot test accuracy by number of neighbors:\n",
    "test_acc = []\n",
    "for i in range(1, int(max_neighbors)):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    test_acc.append(np.mean(cross_val_score(knn, X, y, cv=5)))\n",
    "    \n",
    "print(max(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "\n",
    "len(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot test accuracy by number of neighbors:\n",
    "test_acc_std = []\n",
    "for i in range(1, int(max_neighbors)):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    test_acc_std.append(np.mean(cross_val_score(knn, Xs, y, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(list(range(1, int(max_neighbors))), test_acc, lw=3.)\n",
    "ax.plot(list(range(1, int(max_neighbors))), test_acc_std, lw=3., color='darkred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Highest accuracy is', round(max(test_acc_std),3), ' when k=', test_acc_std.index(max(test_acc_std)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA ANALYSIS\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Instantiate the PCA class and set at 16 components \n",
    "pca = PCA()\n",
    "\n",
    "# Fit PCA with standardised features\n",
    "pca.fit(Xs)\n",
    "\n",
    "len(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative variance explained vs number of components\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_)+1), 100 - (100*pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained cumulative variance %')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cum_var_exp(eig_vals):\n",
    "    '''\n",
    "    Calculate Explained Variance from Eigenvalues\n",
    "    \n",
    "    Return a list or array containing the cumulative explained variance \n",
    "    '''\n",
    "    cum_var_exp=[]\n",
    "    \n",
    "#     for i in np.arange(1,len(eig_vals)):\n",
    "#         expVar = eig_vals[i] / sum(eig_vals[i:len(eig_vals)]) * 100\n",
    "#         cum_var_exp.append(expVar)\n",
    "#         # print(sum(eig_vals[i:len(eig_vals)]))\n",
    "\n",
    "\n",
    "        \n",
    "    for i in sorted(eig_vals,reverse=True):\n",
    "        expVar = i / sum(eig_vals) * 100\n",
    "        cum_var_exp.append(expVar)\n",
    "    \n",
    "    cum_var_exp = np.cumsum(cum_var_exp)\n",
    "    \n",
    "    return cum_var_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_var_exp(eig_vals):\n",
    "    \n",
    "    cum_var_exp = calculate_cum_var_exp(eig_vals)\n",
    "    \n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    component_number = [i+1 for i in range(len(cum_var_exp))]\n",
    "    print(component_number)\n",
    "    \n",
    "    plt.plot(component_number, cum_var_exp, lw=7)\n",
    "\n",
    "    plt.axhline(y=0, linewidth=5, color='grey', ls='dashed')\n",
    "    plt.axhline(y=100, linewidth=3, color='grey', ls='dashed')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([1,30])\n",
    "    ax.set_ylim([-5,105])\n",
    "\n",
    "    ax.set_ylabel('cumulative variance explained', fontsize=16)\n",
    "    ax.set_xlabel('component', fontsize=16)\n",
    "\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(12) \n",
    "\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(12) \n",
    "\n",
    "    ax.set_title('component vs cumulative variance explained\\n', fontsize=20)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var_exp(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=16)\n",
    "pca.fit(Xs)\n",
    "principleComponents = pca.transform(Xs)\n",
    "\n",
    "pca_df = pd.DataFrame(principleComponents)\n",
    "pca_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PC1 vs PC2\n",
    "plt.scatter(principleComponents[:, 0], principleComponents[:, 1])\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Split Data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_df,y,test_size=0.2,random_state=42)\n",
    "\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xs,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set KNN classifier to use 5 neighbors\n",
    "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# CV accuracy of KNN using standardised data \n",
    "standard_scores = cross_val_score(knn5, Xs_train, ys_train, cv=5)\n",
    "print(\"Number of features in standardised data:       \", Xs.shape[1])\n",
    "print(\"5-fold CV accuracy using standardised data:    \", standard_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV accuracy of KNN using PCA-transformed data\n",
    "pca_scores = cross_val_score(knn5, X_train, y_train, cv=5)\n",
    "print(\"Number of features in PCA-transformed data:    \", pca_df.shape[1])\n",
    "print(\"5-fold CV accuracy using PCA-transformed data: \", pca_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "score_pca=[]\n",
    "test_range=X_train.shape[0]\n",
    "# test_range = 500\n",
    "\n",
    "for k in np.arange(1,test_range):\n",
    "    knclf_x = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "    score_pca.append(knclf_x.score(X_test,y_test))\n",
    "    \n",
    "# score_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Highest accuracy is', round(max(score_pca),2), ' when k=', score_pca.index(max(score_pca)))\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(np.arange(1,test_range),score_pca, linestyle='dashed',marker='.',markerfacecolor='red', markersize=10)\n",
    "\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    'penalty': ['l1','l2'],\n",
    "    'C': [1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(estimator = log_reg,\n",
    "                       param_grid = lr_params,\n",
    "                       scoring = 'accuracy',\n",
    "                       verbose = 1,\n",
    "                       n_jobs = -1)\n",
    "\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print(grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "        \n",
    "xgb_cfl = xgb.XGBClassifier(n_jobs = -1)\n",
    "\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'n_estimators' : [100, 200, 500, 750],\n",
    "        'learning_rate' : [0.01, 0.02, 0.05, 0.1, 0.25],\n",
    "        'min_child_weight': [1, 5, 7, 10],\n",
    "        'gamma': [0.1, 0.5, 1, 1.5, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5, 10, 12]\n",
    "        }\n",
    "\n",
    "folds = 5\n",
    "param_comb = 800\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb_cfl, param_distributions=params, n_iter=param_comb, scoring='accuracy', n_jobs=-1, cv=5, verbose=3, random_state=42)\n",
    "\n",
    "# Here we go\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "#----------------------------# random_search.fit(X, y)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_metrics(model) :\n",
    "    scores = ['accuracy', 'precision', 'recall']\n",
    "    for sc in scores:\n",
    "        scores = cross_val_score(model, X, y, cv = 5, scoring = sc)\n",
    "        print('[%s] : %0.5f (+/- %0.5f)'%(sc, scores.mean(), scores.std()))\n",
    "        \n",
    "cross_val_metrics(xgb_clf)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb \n",
    "xgb_clf = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                           colsample_bytree=0.8, gamma=1.5, learning_rate=0.05,\n",
    "                           max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,\n",
    "                           n_estimators=200, n_jobs=-1, nthread=None,\n",
    "                           objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "                           reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "                           subsample=0.6)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "y_score = xgb_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbg_score = cross_val_score(xgb_clf, Xs_train, ys_train, cv=5, scoring='recall')\n",
    "xbg_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,target_names,title='Confusion Matrix',cmap=None,\n",
    "                          normalize=False):\n",
    "    import itertools\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, \n",
    "                          normalize    = False,\n",
    "                          target_names = ['Stay','Leave'],\n",
    "                          title        = \"Confusion matrix for one class \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "#combine split dataset back for resampling\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "# negative = train_data[train_data.Attrition==0]\n",
    "# positive = train_data[train_data.Attrition==1]\n",
    "\n",
    "negative = emp[emp.Attrition==0]\n",
    "positive = emp[emp.Attrition==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample minority\n",
    "pos_upsampled = resample(positive,\n",
    "                         replace=True, # sample with replacement\n",
    "                         n_samples=len(negative), # match number in majority class\n",
    "                         random_state=42) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([negative, pos_upsampled])\n",
    "\n",
    "# check new class counts\n",
    "upsampled.Attrition.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample majority\n",
    "neg_downsampled = resample(negative,\n",
    "                         replace=True, # sample with replacement\n",
    "                         n_samples=len(positive), # match number in minority class\n",
    "                         random_state=42) # reproducible results\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([positive, neg_downsampled])\n",
    "\n",
    "# check new class counts\n",
    "downsampled.Attrition.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res = pd.DataFrame(upsampled,columns=feature_cols)\n",
    "\n",
    "y_res = upsampled['Attrition']\n",
    "\n",
    "X_res_train, X_res_test, y_res_train, y_res_test = train_test_split(X_res,y_res,test_size=0.2,random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res_test.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=None)\n",
    "dtc.fit(X_res_train,y_res_train)\n",
    "y_res_pred = dtc.predict(X_res_test)\n",
    "\n",
    "ac = accuracy_score(y_res_test,y_res_pred)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_res_test, y_res_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "print(classification_report(y_res_test, y_res_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=2000)\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "pt = tree.plot_tree(dtc,\n",
    "                impurity = False,\n",
    "                feature_names = X_res_test.columns.values,\n",
    "                class_names = ['No', 'Yes'],\n",
    "                rounded =True,\n",
    "                filled= True )\n",
    "fig.savefig('plot_tree.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb \n",
    "xgb_clf = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                           colsample_bytree=0.8, gamma=1.5, learning_rate=0.05,\n",
    "                           max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,\n",
    "                           n_estimators=200, n_jobs=-1, nthread=None,\n",
    "                           objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "                           reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "                           subsample=0.6)\n",
    "\n",
    "xgb_clf.fit(X_res_train, y_res_train)\n",
    "y_res_pred = xgb_clf.predict(X_res_test)\n",
    "y_score = xgb_clf.predict_proba(X_res_test)[:,1]\n",
    "\n",
    "ac = accuracy_score(y_res_test, y_res_pred)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_res_test, y_res_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "print(classification_report(y_res_test, y_res_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOMFOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(criterion='gini',\n",
    "                                max_depth=13, \n",
    "                                random_state=1)\n",
    "\n",
    "rf_clf.fit(X_res_train,y_res_train)\n",
    "y_res_pred = rf_clf.predict(X_res_test)\n",
    "\n",
    "ac = accuracy_score(y_res_test,y_res_pred)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_res_test, y_res_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "print(classification_report(y_res_test, y_res_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Score \n",
    "y_pred = model.predict(X_test)\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\");\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "gb_clf.fit(X_res_train,y_res_train)\n",
    "y_res_pred = gb_clf.predict(X_res_test)\n",
    "\n",
    "ac = accuracy_score(y_res_test,y_res_pred)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_res_test, y_res_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "print(classification_report(y_res_test, y_res_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf.fit(X_train,y_train)\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "\n",
    "ac = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find fpr, tpr\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred)\n",
    "\n",
    "# Find auc\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot of a ROC curve for class 1 (has_cancer)\n",
    "plt.figure(figsize=[8,8])\n",
    "\n",
    "# Plot fpr, tpr\n",
    "plt.plot(fpr_lr, tpr_lr, color='darkblue', lw = 2, label = 'LR ROC curve (area = %0.2f)' % roc_auc_lr)\n",
    "\n",
    "plt.plot(fpr_svc, tpr_svc, color='darkgreen', lw = 2, label = 'SVC ROC curve (area = %0.2f)' % roc_auc_svc)\n",
    "\n",
    "plt.plot(fpr_nb, tpr_nb, color='darkorange', lw = 2, label = 'NB ROC curve (area = %0.2f)' % roc_auc_nb)\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Receiver Operating Characteristic: M', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
