{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5kmVTG0YluM"
   },
   "source": [
    "# **MINI PROJECT #3**\n",
    "\n",
    "By Chau Tran\n",
    "\n",
    "# **EMPLOYEE TURNOVER PREDICTION AND INFLUENCE FACTORS ANALYSIS**\n",
    "\n",
    "**What are the key influence factors on employee turnover, their costs and how to prevent?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TABLE OF CONTENTS\n",
    "\n",
    "* [SUMMARY](#summary)\n",
    "* [DATASET](#dataset)\n",
    "* [EDA](#eda)\n",
    "* [FEATURE ENGINEERING](#feature_engineering)\n",
    "* [MODELING](#modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt1YMG9hYluV"
   },
   "source": [
    "## SUMMARY<a id=\"summary\"></a>\n",
    "\n",
    "### Data questions\n",
    "What is the adding value of kitchen feature onto house price of Ames between 2007 and 2010?\n",
    "\n",
    "### Stake-holders\n",
    "Marketing manager - House renovation company, property owners\n",
    "\n",
    "### Objectives\n",
    "This analysis examines the Ames Housing dataset and identifies what renovation features that likely bring significant adding values to the house price. In this case, we found kitchen quality as the main  feature that brought significant influence.\n",
    "\n",
    "From building three linear regression models to predict the sale price and pick the best one, we found the adding value of kitchen quality.\n",
    "\n",
    "By improving the kitchen quality, the house value (with the price of 200k before remodelling) could be increased by of 12%. Details of adding values are as below.\n",
    "\n",
    "The findings help renovation company as the stake-holder to design marketing strategy on their renovation services  as well as help the property owners to make decision on whether or not to improve their house value before they sell their houses.\n",
    "\n",
    "### Cost Of Employee Turnover Report\n",
    "\n",
    "![title](figures/Kitchen_addingvalue_roi_01.png)\n",
    "![title](figures/Kitchen_addingvalue_roi_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GzhbBFyYluW"
   },
   "source": [
    "### Dataset<a id=\"dataset\"></a>\n",
    "\n",
    "https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset\n",
    "\n",
    "Train dataset (from train.csv)\n",
    "\n",
    "Rows: 1470\n",
    "\n",
    "Columns: 32\n",
    "\n",
    "Duplicated rows: 0\n",
    "\n",
    "Column names to reformat: 0 \n",
    "\n",
    "Numerical columns: 25\n",
    "\n",
    "Ordinal columns: 14\n",
    "\n",
    "Nominal columns: 7\n",
    "\n",
    "Missing value columns: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, recall_score, precision_score, f1_score, average_precision_score \n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from sklearn.metrics import plot_precision_recall_curve, precision_recall_curve\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sns.set(color_codes = True)\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'IBM-Employee-Attrition.csv'\n",
    "\n",
    "# import cafe listings into dataframe\n",
    "emp = pd.read_csv(data_file)\n",
    "\n",
    "emp = emp.drop(columns=['EmployeeCount', 'EmployeeNumber','Over18','StandardHours'])\n",
    "\n",
    "\n",
    "attrition_map={'Yes':1,'No':0}\n",
    "emp['Attrition'] = emp['Attrition'].map(attrition_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA<a id=\"eda\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all numerical columns\n",
    "numerical_dtypes = ['int16','int32', 'int64','float16','float32','float64']\n",
    "num_cols = []\n",
    "for i in emp.columns:\n",
    "    if emp[i].dtype in numerical_dtypes:\n",
    "        num_cols.append(i)\n",
    "        \n",
    "print(len(num_cols))\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all category columns\n",
    "\n",
    "# cat_cols = list(set(emp.columns) - set(num_cols))\n",
    "\n",
    "cat_cols = emp.columns.difference(num_cols)\n",
    "print(len(cat_cols))\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri_yes = emp[emp.Attrition==1]\n",
    "attri_no =  emp[emp.Attrition==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pair_charts(data1, data2, column_list, legend_text,fig_size):\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    fig.subplots_adjust(hspace=1, wspace=0.5, top=0.96)\n",
    "    fig.suptitle('Attrtion Yes vs No')\n",
    "\n",
    "    for i, col in enumerate(list(data1[column_list]),1):\n",
    "        # print(col)\n",
    "        ax = fig.add_subplot(len(column_list), 3, i)\n",
    "        plt.hist(data1[col],alpha=0.8)\n",
    "        plt.hist(data2[col],alpha=0.8)\n",
    "        plt.xlabel('{}'.format(col), size=15,labelpad=12.5)\n",
    "        plt.ylabel('Frequecy', size=15, labelpad=12.5)\n",
    "        plt.legend(legend_text)\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    #figname = 'High vs Low quality houses.png'\n",
    "    # fig.savefig(figname,transparent=False, bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.EducationField.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bar charts of ordinal features \n",
    "cols_to_plot = cat_cols\n",
    "plot_pair_charts(attri_no,attri_yes,cols_to_plot,legend_text=['Attrition No','Attrition Yes'],fig_size=(15, 30))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bar charts of numerical features \n",
    "cols_to_plot = num_cols\n",
    "plot_pair_charts(attri_no,attri_yes,cols_to_plot,legend_text=['Attrition No','Attrition Yes'],fig_size=(15, 80))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_attrition = emp[(emp.Attrition==1)]\n",
    "\n",
    "age_under_25 = emp[(emp.Age<25) & (emp.Attrition==1)]\n",
    "age_25_40 = emp[(emp.Age>=25) & (emp.Age<=40) & (emp.Attrition==1)]\n",
    "age_40_50 = emp[(emp.Age>40) & (emp.Age<=50) & (emp.Attrition==1)]\n",
    "age_above_50 = emp[(emp.Age>50) & (emp.Attrition==1)]\n",
    "\n",
    "\n",
    "age_under_25_male = age_under_25[age_under_25.Gender=='Male']\n",
    "age_under_25_female = age_under_25[age_under_25.Gender=='Female']\n",
    "age_25_40_male = age_25_40[age_25_40.Gender=='Male']\n",
    "age_40_50_male = age_40_50[age_40_50.Gender=='Male']\n",
    "age_above_50_male = age_above_50[age_above_50.Gender=='Male']\n",
    "\n",
    "age_25_40_male_overtime = emp[(emp.Age>=25) & (emp.Age<=40) & (emp.Gender=='Male') & (emp.OverTime=='Yes') & (emp.Attrition==1)].shape[0] \n",
    "\n",
    "attri_by_departments = attri_yes.groupby('Department')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genZ = emp[(emp.Age<=22) & (emp.Attrition==1)]\n",
    "genY_millenials = emp[(emp.Age>=23) & (emp.Age<=38) & (emp.Attrition==1)]\n",
    "genX = emp[(emp.Age>=39) & (emp.Age<=54) & (emp.Attrition==1)]\n",
    "boomers = emp[(emp.Age>54) & (emp.Attrition==1)]\n",
    "\n",
    "genZ_male = genZ[genZ.Gender=='Male']\n",
    "genY_millenials_male = genY_millenials[genY_millenials.Gender=='Male']\n",
    "genX_male = genX[genX.Gender=='Male']\n",
    "boomers_male = boomers[boomers.Gender=='Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_under_25_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_25_40.shape[0] / total_attrition.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_25_40_male / age_25_40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_25_40_male_overtime / age_25_40_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overtime = emp[(emp.OverTime=='Yes') & (emp.Attrition==1)]\n",
    "overtime.shape[0] / total_attrition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTRITION YES vs NO\n",
    "\n",
    "# set data to plot\n",
    "group_names=['Churn', 'No Churn']\n",
    "group_size=[attri_yes.shape[0],attri_no.shape[0]]\n",
    "pcts = [f'{s} {l}\\n\\n({s*100/sum(group_size):.2f}%)' for s,l in zip(group_size, group_names)]\n",
    "\n",
    "# Create colors\n",
    "a, b, =[plt.cm.Reds, plt.cm.Blues]\n",
    "\n",
    "# First Ring (outside)\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis('equal')\n",
    "mypie, _ = ax.pie(group_size, radius=1.3, labels=pcts, colors=[a(0.6), b(0.6)])\n",
    "plt.setp(mypie, width=0.3, edgecolor='white')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data to plot\n",
    "\n",
    "emp_by_department = pd.DataFrame(attri_yes.groupby('Department').agg({'Attrition':'sum'}))\n",
    "# emp_by_department.index\n",
    "# emp_by_department.loc['Sales']\n",
    "# emp_by_department.loc['Sales'].Attrition\n",
    "\n",
    "group_names=[n for n in emp_by_department.index]\n",
    "group_size=[i for i in emp_by_department.Attrition]\n",
    "pcts = [f'{s} {l}\\n\\n({s*100/sum(group_size):.2f}%)' for s,l in zip(group_size, group_names)]\n",
    "\n",
    "# Create colors\n",
    "a, b, c, d =[plt.cm.Blues, plt.cm.Reds, plt.cm.Greens, plt.cm.Purples]\n",
    "\n",
    "# First Ring (outside)\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis('equal')\n",
    "mypie, _ = ax.pie(group_size, radius=1.3, labels=pcts, colors=[a(0.6), b(0.6), c(0.6), d(0.6)])\n",
    "plt.setp( mypie, width=0.3, edgecolor='white')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group_names=['genZ - under 23', 'genY_millenials 23-38', 'genX 39 - 54', 'boomers above 54']\n",
    "group_size=[genZ.shape[0],genY_millenials.shape[0],genX.shape[0],boomers.shape[0]]\n",
    "pcts = [f'{s} {l}\\n\\n({s*100/sum(group_size):.2f}%)' for s,l in zip(group_size, group_names)]\n",
    "\n",
    "\n",
    "subgroup_names=['M', 'F', 'M', 'F', 'M', 'F', 'M', 'F']\n",
    "subgroup_size=[genZ_male.shape[0], genZ.shape[0]-genZ_male.shape[0],\n",
    "               genY_millenials_male.shape[0], genY_millenials.shape[0]-genY_millenials_male.shape[0],\n",
    "               genX_male.shape[0], genX.shape[0]-genX_male.shape[0],\n",
    "               boomers_male.shape[0], boomers.shape[0]-boomers_male.shape[0]\n",
    "              ]\n",
    "\n",
    "# Create colors\n",
    "a, b, c, d =[plt.cm.Blues, plt.cm.Reds, plt.cm.Greens, plt.cm.Purples]\n",
    "\n",
    "# First Ring (outside)\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis('equal')\n",
    "mypie, _ = ax.pie(group_size, radius=1.3, labels=pcts, colors=[a(0.6), b(0.6), c(0.6), d(0.6)])\n",
    "plt.setp( mypie, width=0.3, edgecolor='white')\n",
    "\n",
    "\n",
    "# Second Ring (Inside)\n",
    "mypie2, _ = ax.pie(subgroup_size, radius=1.3-0.3, labels=subgroup_names, labeldistance=0.7, colors=[a(0.5), a(0.2), b(0.5), b(0.2), c(0.5), c(0.2), d(0.5), d(0.2)])\n",
    "plt.setp( mypie2, width=0.4, edgecolor='white')\n",
    "plt.margins(0,0)\n",
    "\n",
    "# show it\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart(train, feature):\n",
    "    leave = train[train['Attrition']==1][feature].value_counts(normalize=True)*100\n",
    "    stay = train[train['Attrition']==0][feature].value_counts(normalize=True)*100\n",
    "    df = pd.DataFrame([leave,stay])\n",
    "    df.index = ['Leave','Stay']\n",
    "    df.plot(kind='bar',stacked=True, figsize=(10,5))\n",
    "    plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart(emp, 'Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart(emp, 'Department')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart(emp, 'BusinessTravel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart(emp, 'EducationField')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime\n",
    "\n",
    "bar_chart(emp, 'JobRole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart(emp, 'MaritalStatus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart(emp, 'OverTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(genY_millenials.MonthlyIncome)\n",
    "plt.hist(genZ.MonthlyIncome)\n",
    "# plt.hist(boomers.MonthlyIncome)\n",
    "\n",
    "# plt.hist(emp.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attri_yes.groupby('JobRole').plot.barh()\n",
    "\n",
    "plt.hist(attri_yes.JobRole)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(emp.JobLevel,emp.Age)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(emp.MonthlyIncome,emp.Age)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(emp.JobRole,emp.MonthlyIncome)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(genY_millenials.Department,genY_millenials.MonthlyIncome)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(emp_wage[emp_wage.Age<38].Age, emp_wage[emp_wage.Age<38].JobRole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBSERVE RELATIONSHIPS BETWEEN MONTHLY INCOME AND OTHER VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MontlyIncome of all numerical columns\n",
    "\n",
    "def plot_multi_charts(data, x_column_list, y, title, y_label, plot_type, figsize):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    fig.subplots_adjust(hspace=0.75, wspace=0.4, top=0.96)\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    for i, col in enumerate(list(data[x_column_list]),1):\n",
    "        \n",
    "        ax = fig.add_subplot(len(x_column_list), 3, i)\n",
    "        \n",
    "        if plot_type == 'scatter':\n",
    "            plt.scatter(x=data[col], y=data[y])\n",
    "            plt.xlabel('{}'.format(col), size=15,labelpad=12.5)\n",
    "            plt.ylabel(y_label, size=15, labelpad=12.5)\n",
    "        elif plot_type == 'bar':\n",
    "            data.groupby(col).agg({y:'mean'}).sort_values(by=y).plot.bar(ax=ax)\n",
    "    \n",
    "#     figname = title + '.png'\n",
    "#     fig.savefig(figname,transparent=False, bbox_inches='tight', dpi=300)\n",
    "   \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe MonthlyIncome of all numerical features in Attrition Yes subset\n",
    "\n",
    "plot_multi_charts(data=attri_yes, x_column_list=num_cols,y='MonthlyIncome', \n",
    "                  title='MonthlyIncome vs numerical features',y_label='MonthlyIncome',plot_type='scatter',figsize=(18,70))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe sale price of all category features in Attrition Yes subset\n",
    "\n",
    "plot_multi_charts(data=attri_yes, x_column_list=cat_cols,y='MonthlyIncome', \n",
    "                  title='MonthlyIncome vs numerical features',y_label='MonthlyIncome',plot_type='scatter',figsize=(18,25))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe average sale price of all category features\n",
    "\n",
    "plot_multi_charts(data=attri_yes, x_column_list=cat_cols, y='MonthlyIncome',\n",
    "                  title='MEAN MonthlyIncome vs nominal features', y_label='Ave Monthly Income',plot_type='bar',figsize=(15,35))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=emp,hue='Attrition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp[(emp.OverTime=='Yes') & (emp.Attrition==1)].shape[0] / emp[(emp.Attrition==1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp['Attrition'].value_counts(normalize=True).plot(kind='bar')\n",
    "\n",
    "xlocs, xlabs = plt.xticks()\n",
    "xlocs=[i+1 for i in range(0,2)]\n",
    "for i, v in enumerate(emp['Attrition'].value_counts(normalize=True)):\n",
    "    plt.text(xlocs[i] - 1.1, v + 0.01, str(round(v,2)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURES ENGINEERING<a id=\"feature_engineering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_map={'Male':1,'Female':0}\n",
    "emp['GenderMale'] = emp['Gender'].map(gender_map)\n",
    "\n",
    "overtime_map={'Yes':1,'No':0}\n",
    "emp['OverTime'] = emp['OverTime'].map(overtime_map)\n",
    "\n",
    "emp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all numerical columns\n",
    "numerical_dtypes = ['int16','int32', 'int64','float16','float32','float64']\n",
    "        \n",
    "num_cols = [i for i in emp.columns if emp[i].dtype in numerical_dtypes]        \n",
    "        \n",
    "print(len(num_cols))\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all category columns\n",
    "emp = emp.drop(columns=['Gender'])\n",
    "cat_cols = emp.columns.difference(num_cols)\n",
    "\n",
    "print(len(cat_cols))\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOT ENCODE nominal cols\n",
    "\n",
    "emp = pd.get_dummies(data = emp, columns = cat_cols)\n",
    "emp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(6,10))\n",
    "sns.heatmap(emp.corr()[['Attrition']].sort_values('Attrition',ascending=False),annot=True, cmap='coolwarm', center=0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(emp.corr()[['Attrition']]).sort_values('Attrition',ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.distplot(emp.MonthlyIncome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skew and kurt\n",
    "print(\"Skewness: %f\" % emp['MonthlyIncome'].skew())\n",
    "print(\"Kurtosis: %f\" % emp['MonthlyIncome'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.MonthlyIncome.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_income_fitler = emp[(emp.MonthlyIncome < 15000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp['MonthlyIncome2'] = np.log1p(emp['MonthlyIncome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_income_fitler['MonthlyIncome3'] = np.log1p(emp_income_fitler['MonthlyIncome'])\n",
    "emp_income_fitler['MonthlyIncome3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.distplot(emp.MonthlyIncome2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skew and kurt\n",
    "print(\"Skewness: %f\" % emp['MonthlyIncome2'].skew())\n",
    "print(\"Kurtosis: %f\" % emp['MonthlyIncome2'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_wage = pd.read_csv(data_file)\n",
    "emp_wage.groupby('JobRole').agg({'HourlyRate':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING<a id=\"modeling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobRole_encoded_cols = [c for c in emp if c.startswith('JobRole_')]\n",
    "Department_encoded_cols = [c for c in emp if c.startswith('Department_')]\n",
    "EducationField_encoded_cols = [c for c in emp if c.startswith('EducationField_')]\n",
    "BusinessTravel_encoded_cols = [c for c in emp if c.startswith('BusinessTravel_')]\n",
    "MaritalStatus_encoded_cols = [c for c in emp if c.startswith('MaritalStatus_')]\n",
    "JobRole_encoded_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols6 = ['MonthlyIncome','JobSatisfaction','EnvironmentSatisfaction','WorkLifeBalance', 'JobInvolvement',\n",
    "           'TrainingTimesLastYear','NumCompaniesWorked','JobLevel', 'StockOptionLevel',\n",
    "           'DistanceFromHome', 'YearsWithCurrManager', 'YearsAtCompany', 'YearsInCurrentRole', \n",
    "           'TotalWorkingYears','Age','OverTime','GenderMale']\n",
    "\n",
    "# feature_cols = cols1 + cols2\n",
    "\n",
    "filter_cols = ['HourlyRate','DailyRate','MonthlyRate']\n",
    "\n",
    "\n",
    "target_col = 'Attrition'\n",
    "\n",
    "# feature_cols = [c for c in emp.columns if c != target_col]\n",
    "\n",
    "# feature_cols = [c for c in emp.columns if (c != target_col) & (c not in filter_cols)]\n",
    "\n",
    "# feature_cols = cols3 + cols4\n",
    "\n",
    "# feature_cols = cols5\n",
    "\n",
    "feature_cols = cols6 + JobRole_encoded_cols + Department_encoded_cols + EducationField_encoded_cols + BusinessTravel_encoded_cols + MaritalStatus_encoded_cols\n",
    "\n",
    "\n",
    "\n",
    "X = emp_income_fitler[feature_cols]\n",
    " \n",
    "y = emp_income_fitler['Attrition']\n",
    "\n",
    "# X = emp[feature_cols]\n",
    "\n",
    "# y = emp['Attrition']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE RESAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "#Oversampling the data\n",
    "smote = SMOTE(random_state = 101)\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "Counter(y_sm)\n",
    "\n",
    "X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_sm, y_sm,test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_ROC_curve(model,X_test,y_test):\n",
    "\n",
    "    # Generate the prediction values for each of the test observations using predict_proba() function rather than just predict\n",
    "    preds = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Store the false positive rate(fpr), true positive rate (tpr) in vectors for use in the graph\n",
    "    fpr, tpr, _ = roc_curve(y_test, preds)\n",
    "\n",
    "    # Store the Area Under the Curve (AUC) so we can annotate our graph with theis metric\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot the ROC Curve\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw = lw, label = 'ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color = 'navy', lw = lw, linestyle = '--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(model, X_test, y_test, y_pred):\n",
    "    \n",
    "    # predict probabilities\n",
    "    pred_probs = model.predict_proba(X_test)\n",
    "    # keep probabilities for the positive outcome only\n",
    "    pred_probs = pred_probs[:, 1]\n",
    "    \n",
    "    print('Accuracy is: ',round(accuracy_score(y_test, y_pred),2))\n",
    "    print('F1 score is: ',round(f1_score(y_test, y_pred),2))\n",
    "    print('Ave PR score: ',round(average_precision_score(y_test, pred_probs),2))\n",
    "\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    sns.heatmap(cm/np.sum(cm),annot=True,fmt='.2%', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    \n",
    "#     print(classification_report(y_test,y_pred,target_names=('Stay','Leave')))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "    plot_precision_recall_curve(model, X_test, y_test)\n",
    "    \n",
    "    plot_ROC_curve(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROSS VALIDATON TEST MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "def cross_val_metrics(model, X_train, X_test, y_train, y_test) :\n",
    "    scores = ['accuracy', 'precision', 'recall', 'f1', 'average_precision','roc_auc']\n",
    "    print('\\n Model:', model)\n",
    "    for sc in scores:\n",
    "        scores = cross_val_score(model, X_train, y_train, cv = 10, scoring = sc)\n",
    "        print('[%s] : %0.5f (+/- %0.5f)'%(sc, scores.mean(), scores.std()))\n",
    "\n",
    "    model.fit( X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('\\n', model, ' - Test score report')\n",
    "    print('\\n', classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_clf = RandomForestClassifier()\n",
    "test = cross_val_metrics(RF_clf,X_train,X_test,y_train,y_test) \n",
    "test = pd.DataFrame(test)\n",
    "test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_metrics2(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    models = [\n",
    "              ('LogReg', LogisticRegression()), \n",
    "              ('RF', RandomForestClassifier()),\n",
    "              ('GB', GradientBoostingClassifier()),\n",
    "              ('XGB', xgb.XGBClassifier()),\n",
    "              ('KNN', KNeighborsClassifier()),\n",
    "              ('NB', GaussianNB())\n",
    "             ] \n",
    "\n",
    "    scoring = ['accuracy', 'precision', 'recall', 'f1', 'average_precision','roc_auc']\n",
    "    train_score_dfs = []\n",
    "    test_score_dfs = []\n",
    "    test_score_dict = {}\n",
    "    target_names = ['No Churn', 'Churn']\n",
    "\n",
    "    for name, model in models:\n",
    "        \n",
    "        # GET TRAIN SCORES\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_results = cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        df1 = pd.DataFrame(cv_results)\n",
    "        df1['model'] = name\n",
    "        train_score_dfs.append(df1)\n",
    "    \n",
    "        # GET TEST SCORES\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        \n",
    "        # predict probabilities\n",
    "        pred_probs = model.predict_proba(X_test)\n",
    "        # keep probabilities for the positive class only\n",
    "        pred_probs = pred_probs[:, 1]\n",
    "        \n",
    "        test_score_dict = {'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "                           'Precision': round(precision_score(y_test, y_pred),2),\n",
    "                           'Recall': round(recall_score(y_test, y_pred),2),\n",
    "                           'F1': round(f1_score(y_test, y_pred),2),\n",
    "                           'Average PC': round(average_precision_score(y_test, pred_probs),2),\n",
    "                           'ROC_AUC': round(roc_auc_score(y_test, y_pred),2)\n",
    "                          }\n",
    "        \n",
    "        df2 = pd.DataFrame.from_dict(test_score_dict, orient='index').transpose()\n",
    "        df2['Model'] = name\n",
    "        test_score_dfs.append(df2)\n",
    "    \n",
    "    # combine all score sets into final df\n",
    "    final_train_scores = pd.concat(train_score_dfs, ignore_index=True)\n",
    "    final_test_scores = pd.concat(test_score_dfs, ignore_index=True)\n",
    "    \n",
    "    return final_train_scores, final_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.84      1.00      0.91       221\n",
      "       Churn       0.83      0.11      0.19        47\n",
      "\n",
      "    accuracy                           0.84       268\n",
      "   macro avg       0.84      0.55      0.55       268\n",
      "weighted avg       0.84      0.84      0.78       268\n",
      "\n",
      "RF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.85      0.98      0.91       221\n",
      "       Churn       0.67      0.21      0.32        47\n",
      "\n",
      "    accuracy                           0.84       268\n",
      "   macro avg       0.76      0.60      0.62       268\n",
      "weighted avg       0.82      0.84      0.81       268\n",
      "\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.83      0.94      0.88       221\n",
      "       Churn       0.19      0.06      0.10        47\n",
      "\n",
      "    accuracy                           0.79       268\n",
      "   macro avg       0.51      0.50      0.49       268\n",
      "weighted avg       0.71      0.79      0.74       268\n",
      "\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.89      0.74      0.81       221\n",
      "       Churn       0.32      0.57      0.41        47\n",
      "\n",
      "    accuracy                           0.71       268\n",
      "   macro avg       0.60      0.66      0.61       268\n",
      "weighted avg       0.79      0.71      0.74       268\n",
      "\n",
      "XGB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.87      0.93      0.90       221\n",
      "       Churn       0.52      0.34      0.41        47\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.69      0.64      0.65       268\n",
      "weighted avg       0.81      0.83      0.81       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_scores, test_scores = cross_val_metrics2(X_train,X_test,y_train,y_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061833</td>\n",
       "      <td>0.017492</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.629421</td>\n",
       "      <td>0.830203</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.071255</td>\n",
       "      <td>0.014561</td>\n",
       "      <td>0.855140</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.395462</td>\n",
       "      <td>0.776485</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063851</td>\n",
       "      <td>0.012201</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.351339</td>\n",
       "      <td>0.730603</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061650</td>\n",
       "      <td>0.011701</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.423967</td>\n",
       "      <td>0.748484</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085737</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>0.826291</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.442221</td>\n",
       "      <td>0.720339</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.308649</td>\n",
       "      <td>0.036426</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.610517</td>\n",
       "      <td>0.821118</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.231881</td>\n",
       "      <td>0.044439</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.608730</td>\n",
       "      <td>0.882426</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.360777</td>\n",
       "      <td>0.042548</td>\n",
       "      <td>0.836449</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.570337</td>\n",
       "      <td>0.825647</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.297048</td>\n",
       "      <td>0.045430</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.630310</td>\n",
       "      <td>0.829973</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.265891</td>\n",
       "      <td>0.046234</td>\n",
       "      <td>0.835681</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.469002</td>\n",
       "      <td>0.740035</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.205906</td>\n",
       "      <td>0.584288</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.020983</td>\n",
       "      <td>0.827103</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.193232</td>\n",
       "      <td>0.628327</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.004326</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.299510</td>\n",
       "      <td>0.643247</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.025420</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.280673</td>\n",
       "      <td>0.638164</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.004585</td>\n",
       "      <td>0.020419</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.206426</td>\n",
       "      <td>0.536252</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.004075</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>0.733645</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.435644</td>\n",
       "      <td>0.398620</td>\n",
       "      <td>0.774317</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.009867</td>\n",
       "      <td>0.724299</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.416961</td>\n",
       "      <td>0.791997</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.412504</td>\n",
       "      <td>0.774856</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.010003</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.519287</td>\n",
       "      <td>0.782462</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.010093</td>\n",
       "      <td>0.699531</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.364638</td>\n",
       "      <td>0.713434</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.173974</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.612959</td>\n",
       "      <td>0.820583</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.173611</td>\n",
       "      <td>0.016622</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.538230</td>\n",
       "      <td>0.835713</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.168663</td>\n",
       "      <td>0.015962</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.602241</td>\n",
       "      <td>0.807902</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.172932</td>\n",
       "      <td>0.015725</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.652347</td>\n",
       "      <td>0.826872</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.180611</td>\n",
       "      <td>0.015490</td>\n",
       "      <td>0.854460</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.527237</td>\n",
       "      <td>0.761770</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_accuracy  test_precision  test_recall   test_f1  test_average_precision  test_roc_auc   model\n",
       "0   0.061833    0.017492       0.864486        0.900000     0.243243  0.382979                0.629421      0.830203  LogReg\n",
       "1   0.071255    0.014561       0.855140        0.500000     0.064516  0.114286                0.395462      0.776485  LogReg\n",
       "2   0.063851    0.012201       0.808411        0.444444     0.100000  0.163265                0.351339      0.730603  LogReg\n",
       "3   0.061650    0.011701       0.799065        0.250000     0.024390  0.044444                0.423967      0.748484  LogReg\n",
       "4   0.085737    0.014209       0.826291        0.400000     0.055556  0.097561                0.442221      0.720339  LogReg\n",
       "5   0.308649    0.036426       0.864486        0.900000     0.243243  0.382979                0.610517      0.821118      RF\n",
       "6   0.231881    0.044439       0.883178        0.750000     0.290323  0.418605                0.608730      0.882426      RF\n",
       "7   0.360777    0.042548       0.836449        0.692308     0.225000  0.339623                0.570337      0.825647      RF\n",
       "8   0.297048    0.045430       0.841121        0.818182     0.219512  0.346154                0.630310      0.829973      RF\n",
       "9   0.265891    0.046234       0.835681        0.545455     0.166667  0.255319                0.469002      0.740035      RF\n",
       "10  0.004328    0.020361       0.799065        0.250000     0.081081  0.122449                0.205906      0.584288     KNN\n",
       "11  0.004505    0.020983       0.827103        0.250000     0.096774  0.139535                0.193232      0.628327     KNN\n",
       "12  0.004326    0.021100       0.822430        0.600000     0.150000  0.240000                0.299510      0.643247     KNN\n",
       "13  0.004357    0.025420       0.803738        0.461538     0.146341  0.222222                0.280673      0.638164     KNN\n",
       "14  0.004585    0.020419       0.816901        0.384615     0.138889  0.204082                0.206426      0.536252     KNN\n",
       "15  0.004075    0.010186       0.733645        0.343750     0.594595  0.435644                0.398620      0.774317     GNB\n",
       "16  0.004084    0.009867       0.724299        0.315789     0.774194  0.448598                0.416961      0.791997     GNB\n",
       "17  0.004285    0.010157       0.766355        0.416667     0.625000  0.500000                0.412504      0.774856     GNB\n",
       "18  0.004260    0.010003       0.728972        0.392405     0.756098  0.516667                0.519287      0.782462     GNB\n",
       "19  0.004152    0.010093       0.699531        0.310811     0.638889  0.418182                0.364638      0.713434     GNB\n",
       "20  0.173974    0.016732       0.873832        0.750000     0.405405  0.526316                0.612959      0.820583     XGB\n",
       "21  0.173611    0.016622       0.864486        0.562500     0.290323  0.382979                0.538230      0.835713     XGB\n",
       "22  0.168663    0.015962       0.859813        0.750000     0.375000  0.500000                0.602241      0.807902     XGB\n",
       "23  0.172932    0.015725       0.859813        0.703704     0.463415  0.558824                0.652347      0.826872     XGB\n",
       "24  0.180611    0.015490       0.854460        0.608696     0.388889  0.474576                0.527237      0.761770     XGB"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GNB</th>\n",
       "      <td>0.005514</td>\n",
       "      <td>0.012357</td>\n",
       "      <td>0.730560</td>\n",
       "      <td>0.355884</td>\n",
       "      <td>0.677755</td>\n",
       "      <td>0.463818</td>\n",
       "      <td>0.422402</td>\n",
       "      <td>0.767413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.005720</td>\n",
       "      <td>0.025136</td>\n",
       "      <td>0.813848</td>\n",
       "      <td>0.389231</td>\n",
       "      <td>0.122617</td>\n",
       "      <td>0.185658</td>\n",
       "      <td>0.237149</td>\n",
       "      <td>0.606056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.064701</td>\n",
       "      <td>0.017888</td>\n",
       "      <td>0.830679</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>0.097541</td>\n",
       "      <td>0.160507</td>\n",
       "      <td>0.448482</td>\n",
       "      <td>0.761223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.330024</td>\n",
       "      <td>0.050215</td>\n",
       "      <td>0.854056</td>\n",
       "      <td>0.764231</td>\n",
       "      <td>0.226443</td>\n",
       "      <td>0.347219</td>\n",
       "      <td>0.586326</td>\n",
       "      <td>0.828305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.199756</td>\n",
       "      <td>0.016385</td>\n",
       "      <td>0.862481</td>\n",
       "      <td>0.674980</td>\n",
       "      <td>0.384606</td>\n",
       "      <td>0.488539</td>\n",
       "      <td>0.586603</td>\n",
       "      <td>0.810568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fit_time  score_time  test_accuracy  test_precision  test_recall   test_f1  test_average_precision  test_roc_auc\n",
       "model                                                                                                                   \n",
       "GNB     0.005514    0.012357       0.730560        0.355884     0.677755  0.463818                0.422402      0.767413\n",
       "KNN     0.005720    0.025136       0.813848        0.389231     0.122617  0.185658                0.237149      0.606056\n",
       "LogReg  0.064701    0.017888       0.830679        0.498889     0.097541  0.160507                0.448482      0.761223\n",
       "RF      0.330024    0.050215       0.854056        0.764231     0.226443  0.347219                0.586326      0.828305\n",
       "XGB     0.199756    0.016385       0.862481        0.674980     0.384606  0.488539                0.586603      0.810568"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores.groupby('model').mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Average PC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.60</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.66</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.64</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision  Recall    F1  Average PC  ROC_AUC   Model\n",
       "0      0.84       0.83    0.11  0.19        0.41     0.55  LogReg\n",
       "1      0.84       0.58    0.23  0.33        0.43     0.60      RF\n",
       "2      0.79       0.19    0.06  0.10        0.18     0.50     KNN\n",
       "3      0.71       0.32    0.57  0.41        0.42     0.66     GNB\n",
       "4      0.83       0.52    0.34  0.41        0.44     0.64     XGB"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Average PC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.71</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.56</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.56</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision  Recall    F1  Average PC  ROC_AUC   Model\n",
       "0      0.89       0.65    0.51  0.57        0.63     0.73  LogReg\n",
       "4      0.88       0.62    0.46  0.53        0.63     0.71     XGB\n",
       "1      0.89       0.80    0.31  0.44        0.62     0.65      RF\n",
       "3      0.30       0.16    0.92  0.28        0.37     0.56     GNB\n",
       "2      0.85       0.50    0.15  0.24        0.27     0.56     KNN"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = cross_val_metrics2(Xs_train,Xs_test,ys_train,ys_test) \n",
    "final.sort_values(['F1','Average PC'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Average PC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.81</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.69</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.80</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision  Recall    F1  Average PC  ROC_AUC   Model\n",
       "0      0.81       0.85    0.77  0.81        0.87     0.81  LogReg\n",
       "1      0.92       0.95    0.88  0.91        0.97     0.92      RF\n",
       "2      0.69       0.68    0.72  0.70        0.71     0.69     KNN\n",
       "3      0.80       0.76    0.87  0.81        0.93     0.80     GNB\n",
       "4      0.93       0.95    0.90  0.92        0.98     0.93     XGB"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = cross_val_metrics2(X_train_sm,X_test_sm,y_train_sm,y_test_sm)   \n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.88      0.97      0.92       219\n",
      "       Churn       0.97      0.87      0.92       223\n",
      "\n",
      "    accuracy                           0.92       442\n",
      "   macro avg       0.92      0.92      0.92       442\n",
      "weighted avg       0.92      0.92      0.92       442\n",
      "\n",
      "RF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.89      0.95      0.92       219\n",
      "       Churn       0.95      0.88      0.91       223\n",
      "\n",
      "    accuracy                           0.91       442\n",
      "   macro avg       0.92      0.91      0.91       442\n",
      "weighted avg       0.92      0.91      0.91       442\n",
      "\n",
      "GB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.88      0.96      0.92       219\n",
      "       Churn       0.96      0.87      0.91       223\n",
      "\n",
      "    accuracy                           0.91       442\n",
      "   macro avg       0.92      0.91      0.91       442\n",
      "weighted avg       0.92      0.91      0.91       442\n",
      "\n",
      "XGB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.90      0.95      0.93       219\n",
      "       Churn       0.95      0.90      0.92       223\n",
      "\n",
      "    accuracy                           0.93       442\n",
      "   macro avg       0.93      0.93      0.93       442\n",
      "weighted avg       0.93      0.93      0.93       442\n",
      "\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.89      0.92      0.90       219\n",
      "       Churn       0.92      0.88      0.90       223\n",
      "\n",
      "    accuracy                           0.90       442\n",
      "   macro avg       0.90      0.90      0.90       442\n",
      "weighted avg       0.90      0.90      0.90       442\n",
      "\n",
      "NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.87      0.41      0.56       219\n",
      "       Churn       0.62      0.94      0.75       223\n",
      "\n",
      "    accuracy                           0.68       442\n",
      "   macro avg       0.75      0.68      0.65       442\n",
      "weighted avg       0.75      0.68      0.65       442\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Average PC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.91</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.91</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.68</td>\n",
       "      <td>NB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision  Recall    F1  Average PC  ROC_AUC   Model\n",
       "3      0.93       0.95    0.90  0.92        0.98     0.93     XGB\n",
       "0      0.92       0.97    0.87  0.92        0.97     0.92  LogReg\n",
       "1      0.91       0.95    0.88  0.91        0.97     0.91      RF\n",
       "2      0.91       0.96    0.87  0.91        0.97     0.91      GB\n",
       "4      0.90       0.92    0.88  0.90        0.95     0.90     KNN\n",
       "5      0.68       0.62    0.94  0.75        0.92     0.68      NB"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final1, final2 = cross_val_metrics2(Xs_train_sm, Xs_test_sm, ys_train_sm, ys_test_sm) \n",
    "final2.sort_values(['ROC_AUC','Recall'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GNB</th>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1\n",
       "model       \n",
       "GNB    0.515"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.groupby('model').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST WITH UNBALANCED DATA BEFORE NORMALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model: LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[accuracy] : 0.82508 (+/- 0.01661)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[precision] : 0.48095 (+/- 0.40641)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[recall] : 0.05380 (+/- 0.04776)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[f1] : 0.09384 (+/- 0.08250)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[average_precision] : 0.42489 (+/- 0.07776)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chautran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[roc_auc] : 0.74366 (+/- 0.04834)\n",
      "\n",
      " LogisticRegression()  - Test score report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       221\n",
      "           1       0.83      0.11      0.19        47\n",
      "\n",
      "    accuracy                           0.84       268\n",
      "   macro avg       0.84      0.55      0.55       268\n",
      "weighted avg       0.84      0.84      0.78       268\n",
      "\n",
      "\n",
      " Model: RandomForestClassifier()\n",
      "[accuracy] : 0.85407 (+/- 0.01625)\n",
      "[precision] : 0.80000 (+/- 0.20710)\n",
      "[recall] : 0.20614 (+/- 0.10004)\n",
      "[f1] : 0.31745 (+/- 0.08970)\n",
      "[average_precision] : 0.56973 (+/- 0.06353)\n",
      "[roc_auc] : 0.80588 (+/- 0.04263)\n",
      "\n",
      " RandomForestClassifier()  - Test score report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91       221\n",
      "           1       0.59      0.21      0.31        47\n",
      "\n",
      "    accuracy                           0.84       268\n",
      "   macro avg       0.72      0.59      0.61       268\n",
      "weighted avg       0.81      0.84      0.80       268\n",
      "\n",
      "\n",
      " Model: GradientBoostingClassifier()\n",
      "[accuracy] : 0.86437 (+/- 0.01326)\n",
      "[precision] : 0.70747 (+/- 0.07746)\n",
      "[recall] : 0.37778 (+/- 0.07943)\n",
      "[f1] : 0.48803 (+/- 0.06164)\n",
      "[average_precision] : 0.60637 (+/- 0.02682)\n",
      "[roc_auc] : 0.82649 (+/- 0.02552)\n",
      "\n",
      " GradientBoostingClassifier()  - Test score report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90       221\n",
      "           1       0.48      0.30      0.37        47\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.67      0.61      0.63       268\n",
      "weighted avg       0.80      0.82      0.80       268\n",
      "\n",
      "\n",
      " Model: GaussianNB()\n",
      "[accuracy] : 0.72967 (+/- 0.03738)\n",
      "[precision] : 0.35065 (+/- 0.05560)\n",
      "[recall] : 0.65497 (+/- 0.11140)\n",
      "[f1] : 0.45578 (+/- 0.07067)\n",
      "[average_precision] : 0.40966 (+/- 0.11073)\n",
      "[roc_auc] : 0.73977 (+/- 0.07862)\n",
      "\n",
      " GaussianNB()  - Test score report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.74      0.81       221\n",
      "           1       0.32      0.57      0.41        47\n",
      "\n",
      "    accuracy                           0.71       268\n",
      "   macro avg       0.60      0.66      0.61       268\n",
      "weighted avg       0.79      0.71      0.74       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LG_clf = LogisticRegression()\n",
    "cross_val_metrics(LG_clf,X_train,X_test,y_train,y_test)   \n",
    "\n",
    "RF_clf = RandomForestClassifier()\n",
    "cross_val_metrics(RF_clf,X_train,X_test,y_train,y_test) \n",
    "\n",
    "GB_clf = GradientBoostingClassifier()\n",
    "cross_val_metrics(GB_clf,X_train,X_test,y_train,y_test)  \n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "cross_val_metrics(NB_clf,X_train,X_test,y_train,y_test) \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST WITH UNBALANCED DATA AFTER NORMALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xs,y,test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_clf = xgb.XGBClassifier(scale_pos_weight=5.2)\n",
    "cross_val_metrics(XGB_clf,Xs_train,Xs_test,ys_train,ys_test) \n",
    "\n",
    "LG_clf = LogisticRegression()\n",
    "cross_val_metrics(LG_clf,Xs_train,Xs_test,ys_train,ys_test)   \n",
    "\n",
    "RF_clf = RandomForestClassifier(class_weight='balanced')\n",
    "cross_val_metrics(RF_clf,Xs_train,Xs_test,ys_train,ys_test)   \n",
    "\n",
    "GB_clf = GradientBoostingClassifier()\n",
    "cross_val_metrics(GB_clf,Xs_train,Xs_test,ys_train,ys_test)   \n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "cross_val_metrics(NB_clf,Xs_train,Xs_test,ys_train,ys_test)   \n",
    "\n",
    "\n",
    "KN_clf = KNeighborsClassifier()\n",
    "cross_val_metrics(KN_clf,Xs_train,Xs_test,ys_train,ys_test) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST WITH SMOTE SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST WITH SMOTE SAMPLE\n",
    "\n",
    "XGB_clf = xgb.XGBClassifier()\n",
    "cross_val_metrics(XGB_clf,X_train_sm,X_test_sm,y_train_sm,y_test_sm)   \n",
    "\n",
    "LG_clf = LogisticRegression()\n",
    "cross_val_metrics(LG_clf,X_train_sm,X_test_sm,y_train_sm,y_test_sm)   \n",
    "\n",
    "RF_clf = RandomForestClassifier()\n",
    "cross_val_metrics(RF_clf,X_train_sm,X_test_sm,y_train_sm,y_test_sm) \n",
    "\n",
    "GB_clf = GradientBoostingClassifier()\n",
    "cross_val_metrics(GB_clf,X_train_sm,X_test_sm,y_train_sm,y_test_sm)  \n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "cross_val_metrics(NB_clf,X_train_sm,X_test_sm,y_train_sm,y_test_sm) \n",
    "\n",
    "KN_clf = KNeighborsClassifier()\n",
    "cross_val_metrics(KN_clf,X_train_sm,X_test_sm,y_train_sm,y_test_sm) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST WITH SMOTE SAMPLE - NORMALISED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "Xs_sm = ss.fit_transform(X_sm)\n",
    "Xs_train_sm, Xs_test_sm, ys_train_sm, ys_test_sm = train_test_split(Xs_sm,y_sm,test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST WITH SMOTE SAMPLE - NORMALISED\n",
    "\n",
    "XGB_clf = xgb.XGBClassifier()\n",
    "cross_val_metrics(XGB_clf,Xs_train_sm, Xs_test_sm, ys_train_sm, ys_test_sm) \n",
    "\n",
    "LG_clf = LogisticRegression()\n",
    "cross_val_metrics(LG_clf,Xs_train_sm, Xs_test_sm, ys_train_sm, ys_test_sm)   \n",
    "\n",
    "RF_clf = RandomForestClassifier()\n",
    "cross_val_metrics(RF_clf,Xs_train_sm, Xs_test_sm, ys_train_sm, ys_test_sm)   \n",
    "\n",
    "GB_clf = GradientBoostingClassifier()\n",
    "cross_val_metrics(GB_clf,Xs_train_sm, Xs_test_sm, ys_train_sm, ys_test_sm)   \n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "cross_val_metrics(NB_clf,Xs_train_sm, Xs_test_sm, ys_train_sm, ys_test_sm)  \n",
    "\n",
    "KN_clf = KNeighborsClassifier()\n",
    "cross_val_metrics(KN_clf,Xs_train_sm, Xs_test_sm, ys_train_sm, ys_test_sm)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERPARAMETERS TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cfl = xgb.XGBClassifier(n_jobs = -1)\n",
    "\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "param_grid = {\n",
    "        'n_estimators' : [100, 200],\n",
    "        'learning_rate' : [0.01, 0.02, 0.05, 0.1, 0.25],\n",
    "        'min_child_weight': [1, 5, 7, 10],\n",
    "        'gamma': [0.1, 0.5, 1, 1.5, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5, 10, 12]\n",
    "        }\n",
    "\n",
    "folds = 5\n",
    "param_comb = 800\n",
    "\n",
    "grid_search = GridSearchCV(estimator = xgb_cfl, param_grid = param_grid,cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(Xs_train_sm,ys_train_sm)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000],\n",
    "    'class_weight':['balanced']\n",
    "}\n",
    "\n",
    "#  'max_features': [2, 3],\n",
    "\n",
    "\n",
    "# Create a based model\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "# cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = RF, param_grid = param_grid,cv = 5, n_jobs = -1, verbose = 2, scoring='recall')\n",
    "grid_search.fit(Xs_train_sm,ys_train_sm)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    \"n_estimators\":[5,50,100,250,500,600],\n",
    "    \"max_depth\":[1,3,5,7,9],\n",
    "    \"learning_rate\":[0.01,0.1,1,10,100]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "# cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = gb, param_grid = param_grid,cv = 5, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(Xs_train_sm,ys_train_sm)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "# param_grid = {'penalty' : ['l1', 'l2'],\n",
    "#                 'C' : np.logspace(-4, 4, 20),\n",
    "#                 'solver' : ['liblinear']}\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "param_grid = {'penalty' : ['l1', 'l2'],\n",
    "                'C' : [100, 10, 1.0, 0.1, 0.01],\n",
    "                'solver' : ['newton-cg', 'lbfgs', 'liblinear']}\n",
    "\n",
    "\n",
    "# Create a based model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = lr, param_grid = param_grid,cv = cv, n_jobs = -1, verbose = 2)\n",
    "grid_result = grid_search.fit(X_train,y_train)\n",
    "grid_search.best_params_\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST MODELS WITH TUNED HYPERPARAMETERS USING RESAMPLED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_feature_importance(model, X):\n",
    "    importances =model.feature_importances_\n",
    "\n",
    "    imp_dict = dict(zip(X.columns, importances))\n",
    "    score_df = pd.DataFrame(imp_dict.items(), columns=['feature', 'score'])\n",
    "    score_df = score_df.sort_values('score',ascending=False)\n",
    "    print(score_df.head(10))\n",
    "\n",
    "    # plot the scores\n",
    "    fig = plt.figure(figsize=(4,9))\n",
    "    score_df = score_df.sort_values('score',ascending=True)\n",
    "    plt.barh(score_df.feature, score_df.score)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    \n",
    "     # figname = 'Feature importance.png'\n",
    "    # fig.savefig(figname,transparent=False, bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    return score_df\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb \n",
    "\n",
    "# xgb_clf = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#                            colsample_bytree=0.8, gamma=1.5, learning_rate=0.05,\n",
    "#                            max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,\n",
    "#                            n_estimators=200, n_jobs=-1, nthread=None,\n",
    "#                            objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "#                            reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "#                            subsample=0.6)\n",
    "\n",
    "# xgb_clf = xgb.XGBClassifier(colsample_bytree=0.8, gamma=1.5, learning_rate=0.05,\n",
    "#                            max_depth=3, n_estimators=200, n_jobs=-1, \n",
    "#                            random_state=42)\n",
    "\n",
    "# xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "XGB_clf = xgb.XGBClassifier(colsample_bytree=0.6,\n",
    "                             gamma=1,\n",
    "                             learning_rate= 0.1,\n",
    "                             max_depth=12,\n",
    "                             min_child_weight=1,\n",
    "                             n_estimators=200,\n",
    "                             subsample=1.0)\n",
    "\n",
    "XGB_clf.fit(Xs_train_sm,ys_train_sm)\n",
    "ys_pred_sm = XGB_clf.predict(Xs_test_sm)\n",
    "display_scores(XGB_clf, Xs_test_sm, ys_test_sm, ys_pred_sm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_score_df = display_feature_importance(XGB_clf, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "per_imp = permutation_importance(XGB_clf, Xs_train_sm,ys_train_sm, scoring='recall')\n",
    "importances = per_imp.importances_mean\n",
    "    \n",
    "imp_dict = dict(zip(X.columns, importances))\n",
    "score_df = pd.DataFrame(imp_dict.items(), columns=['feature', 'score'])\n",
    "score_df = score_df.sort_values('score',ascending=False)\n",
    "print(score_df.head(10))\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure(figsize=(4,9))\n",
    "score_df = score_df.sort_values('score',ascending=True)\n",
    "plt.barh(score_df.feature, score_df.score)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "\n",
    "# Create an instance of SelectKBest\n",
    "kbest = SelectKBest(score_func=chi2, k=4)\n",
    "\n",
    "# Fit \n",
    "fit = kbest.fit(X, y)\n",
    "\n",
    "# Print Score \n",
    "# Find Top 4 Features\n",
    "importance = pd.DataFrame(fit.scores_, index=feature_cols, columns=['score'])\n",
    "\n",
    "importance.sort_values('score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST CLASSIFIER TUNED\n",
    "\n",
    "# RF_clf = RandomForestClassifier(bootstrap=True,\n",
    "#                                  max_depth=20,\n",
    "#                                  max_features='sqrt',\n",
    "#                                  min_samples_leaf=2,\n",
    "#                                  min_samples_split=2,\n",
    "#                                  n_estimators=1200)\n",
    "\n",
    "\n",
    "# RF_clf = RandomForestClassifier(bootstrap=True,\n",
    "#                                  max_depth=90,\n",
    "#                                  max_features=3,\n",
    "#                                  min_samples_leaf=3,\n",
    "#                                  min_samples_split=8,\n",
    "#                                  n_estimators=1000)\n",
    "\n",
    "\n",
    "# RF_clf = RandomForestClassifier(bootstrap=True,\n",
    "#                                  max_depth=90,\n",
    "#                                  max_features='auto',\n",
    "#                                  min_samples_leaf=3,\n",
    "#                                  min_samples_split=8,\n",
    "#                                  n_estimators=100)\n",
    "# 'bootstrap': True,\n",
    "#  'class_weight': 'balanced',\n",
    "#  'max_depth': 90,\n",
    "#  'max_features': 'auto',\n",
    "#  'min_samples_leaf': 3,\n",
    "#  'min_samples_split': 8,\n",
    "#  'n_estimators': 100}\n",
    "\n",
    "RF_clf = RandomForestClassifier(class_weight='balanced')\n",
    "    \n",
    "RF_clf.fit(Xs_train_sm,ys_train_sm)\n",
    "ys_pred_sm = RF_clf.predict(Xs_test_sm)\n",
    "display_scores(RF_clf, Xs_test_sm, ys_test_sm, ys_pred_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_score_df = display_feature_importance(RF_clf, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRADIENT BOOSTING\n",
    "\n",
    "\n",
    "# {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n",
    "#  0.1, 'max_depth': 1, 'n_estimators': 500\n",
    "# 'learning_rate': 1, 'max_depth': 5, 'n_estimators': 500\n",
    "            \n",
    "GB_clf = GradientBoostingClassifier(random_state=42, \n",
    "                                    learning_rate=1, \n",
    "                                    max_depth=5, \n",
    "                                    n_estimators=500)\n",
    "\n",
    "\n",
    "GB_clf.fit(Xs_train_sm,ys_train_sm)\n",
    "ys_pred_sm = GB_clf.predict(Xs_test_sm)\n",
    "display_scores(GB_clf, Xs_test_sm, ys_test_sm, ys_pred_sm)\n",
    "GB_score_df = display_feature_importance(GB_clf, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_model = LogisticRegression(solver='newton-cg',C=1.0,penalty='l2')\n",
    "\n",
    "log_model.fit(Xs_train_sm,ys_train_sm)\n",
    "ys_pred_sm = log_model.predict(Xs_test_sm)\n",
    "display_scores(log_model, Xs_test_sm, ys_test_sm, ys_pred_sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import matplotlib\n",
    "import squarify # pip install squarify (algorithm for treemap)\n",
    "\n",
    "size_list = list(RF_score_df.score.head(10))\n",
    "label_list = list(RF_score_df.feature.head(10))\n",
    "\n",
    "# create a color palette, mapped to these values\n",
    "cmap = matplotlib.cm.Reds\n",
    "mini=min(size_list)\n",
    "maxi=max(size_list)\n",
    "norm = matplotlib.colors.Normalize(vmin=mini, vmax=maxi)\n",
    "colors = [cmap(norm(value)) for value in size_list]\n",
    "\n",
    "# colors=['Red','Yellow','Green', 'Purple']\n",
    "\n",
    "squarify.plot(sizes=size_list, label=label_list, color=colors, alpha=.4 )\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred is an array of predictions\n",
    "def bestThresshold(y_true,y_pred):\n",
    "    best_thresh = None\n",
    "    best_score = 0\n",
    "    for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "        \n",
    "        score = f1_score(y_true, np.array(y_pred)>thresh)\n",
    "#         print(thresh)\n",
    "#         print(np.array(y_pred)>thresh)\n",
    "#         print(score)\n",
    "        if score > best_score:\n",
    "            best_thresh = thresh\n",
    "            best_score = score\n",
    "    return best_score , best_thresh\n",
    "\n",
    "best_score , best_thresh = bestThresshold(ys_test_sm, ys_pred_sm)\n",
    "print(best_score , best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_clf = xgb.XGBClassifier(scale_pos_weight=5.2)\n",
    "cross_val_metrics(XGB_clf,Xs_train,Xs_test,ys_train,ys_test) \n",
    "\n",
    "best_score , best_thresh = bestThresshold(ys_test, y_pred)\n",
    "print(best_score , best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_curve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
